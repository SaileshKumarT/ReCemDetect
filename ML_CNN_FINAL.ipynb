{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import cv2\n",
    "import numpy\n",
    "\n",
    "\n",
    "# Create an ImageDataGenerator object for data augmentation and rescaling\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # normalize pixel values to be between 0 and 1\n",
    "    rotation_range=20,  # randomly rotate images by up to 20 degrees\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally by up to 20% of the width\n",
    "    height_shift_range=0.2,  # randomly shift images vertically by up to 20% of the height\n",
    "    shear_range=0.2,  # randomly shear images by up to 20%\n",
    "    zoom_range=0.2,  # randomly zoom images by up to 20%\n",
    "    horizontal_flip=True,  # randomly flip images horizontally\n",
    "    fill_mode='nearest'  # fill in any missing pixels with the nearest available pixel\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 265 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Use the flow_from_directory method to load data from your dataset directory and apply data augmentation\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    '/home/tsaileshkumar/ML_Project/dataset/train',  # path to the directory containing your training images\n",
    "    target_size=(180, 180),  # resize images to be 150x150 pixels\n",
    "    batch_size=1,  # process images in batches of 32\n",
    "    class_mode='binary'  # use binary classification (2 classes)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 67 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Use the flow_from_directory method to load data from your dataset directory without data augmentation\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    '/home/tsaileshkumar/ML_Project/dataset/test',  # path to the directory containing your test images\n",
    "    target_size=(180, 180),  # resize images to be 180x180 pixels\n",
    "    batch_size=32,  # process images in batches of 32\n",
    "    class_mode='binary'  # use binary classification (2 classes)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of samples in the training and test sets\n",
    "num_train_samples = len(train_generator.filenames)\n",
    "num_test_samples = len(test_generator.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of training and test steps per epoch\n",
    "train_steps_per_epoch = np.ceil(num_train_samples / train_generator.batch_size)\n",
    "test_steps_per_epoch = np.ceil(num_test_samples / test_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "265/265 [==============================] - 14s 48ms/step - loss: 0.6213 - accuracy: 0.6981 - val_loss: 0.6118 - val_accuracy: 0.7015\n",
      "Epoch 2/5\n",
      "265/265 [==============================] - 12s 45ms/step - loss: 0.6439 - accuracy: 0.7057 - val_loss: 0.6087 - val_accuracy: 0.7015\n",
      "Epoch 3/5\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.6543 - accuracy: 0.7057 - val_loss: 0.6379 - val_accuracy: 0.7015\n",
      "Epoch 4/5\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.8437 - accuracy: 0.7057 - val_loss: 0.6318 - val_accuracy: 0.7015\n",
      "Epoch 5/5\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.6302 - accuracy: 0.7057 - val_loss: 0.6096 - val_accuracy: 0.7015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1eedb1c350>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define some data augmentation parameters\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#     rescale=1./255,  # normalize pixel values to be between 0 and 1\n",
    "#     rotation_range=20,  # randomly rotate images by up to 20 degrees\n",
    "#     width_shift_range=0.2,  # randomly shift images horizontally by up to 20% of the width\n",
    "#     height_shift_range=0.2,  # randomly shift images vertically by up to 20% of the height\n",
    "#     shear_range=0.2,  # randomly shear images by up to 20%\n",
    "#     zoom_range=0.2,  # randomly zoom images by up to 20%\n",
    "#     horizontal_flip=True,  # randomly flip images horizontally\n",
    "#     fill_mode='nearest'  # fill in any missing pixels with the nearest available pixel\n",
    "# )\n",
    "\n",
    "# validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# # Load the training data from a directory on your local machine\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#     '/path/to/train/directory',  # path to the directory containing your training images\n",
    "#     target_size=(150, 150),  # resize images to be 150x150 pixels\n",
    "#     batch_size=32,  # process images in batches of 32\n",
    "#     class_mode='binary'  # use binary classification (2 classes)\n",
    "# )\n",
    "\n",
    "# # Load the validation data from a directory on your local machine\n",
    "# validation_generator = validation_datagen.flow_from_directory(\n",
    "#     '/path/to/validation/directory',  # path to the directory containing your validation images\n",
    "#     target_size=(150, 150),  # resize images to be 150x150 pixels\n",
    "#     batch_size=32,  # process images in batches of 32\n",
    "#     class_mode='binary'  # use binary classification (2 classes)\n",
    "# )\n",
    "\n",
    "# Define the model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(180, 180, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "# history = model.fit(train_generator, epochs=10, \n",
    "#                     validation_data=validation_generator)\n",
    "\n",
    "# Train the model using the training generator\n",
    "model.fit(train_generator, steps_per_epoch=train_steps_per_epoch, epochs=5, \n",
    "          validation_data=test_generator, validation_steps=test_steps_per_epoch)\n",
    "\n",
    "# Evaluate the model\n",
    "# test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
    "# print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"94.png\", cv2.IMREAD_COLOR)\n",
    "img.resize(180,180,3)\n",
    "img = img[numpy.newaxis,:,:]\n",
    "prediction = model.predict(img)\n",
    "numpy.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "archive ='/home/tsaileshkumar/ML_Project/dataset_1'\n",
    "# data_dir = pathlib.Path(archive).with_suffix('')\n",
    "data_dir = pathlib.Path(archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebars = list(data_dir.glob('rebars/*'))\n",
    "PIL.Image.open(str(rebars[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
